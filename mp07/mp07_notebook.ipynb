{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS440/ECE448 Spring 2023\n",
    "# MP07: First-Order Logic, Unification, and Backward-Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing you need to do is to download this file: <a href=\"mp07.zip\">mp07.zip</a>.  It has the following content:\n",
    "\n",
    "* `submitted.py`: Your homework. Edit, and then submit to <a href=\"https://www.gradescope.com/courses/486387\">Gradescope</a>.\n",
    "* `mp07_notebook.ipynb`: This is a <a href=\"https://anaconda.org/anaconda/jupyter\">Jupyter</a> notebook to help you debug.  You can completely ignore it if you want, although you might find that it gives you useful instructions.\n",
    "* `grade.py`: Once your homework seems to be working, you can test it by typing `python grade.py`, which will run the tests in `tests/tests_visible.py`.\n",
    "* `tests/test_visible.py`: This file contains about half of the <a href=\"https://docs.python.org/3/library/unittest.html\">unit tests</a> that Gradescope will run in order to grade your homework.  If you can get a perfect score on these tests, then you should also get a perfect score on the additional hidden tests that Gradescope uses.\n",
    "* `data`: This directory contains the data.\n",
    "* `reader.py`: This is an auxiliary program that you can use to read the data.\n",
    "* `requirements.txt`: This tells you which python packages you need to have installed, in order to run `grade.py`.  You can install all of those packages by typing `pip install -r requirements.txt` or `pip3 install -r requirements.txt`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This file (`mp07_notebook.ipynb`) will walk you through the whole MP, giving you instructions and debugging tips as you go.\n",
    "\n",
    "### Table of Contents\n",
    "\n",
    "1. <a href=\"#section1\">Reading the data</a>\n",
    "1. <a href=\"#section2\">Standardize Variables</a>\n",
    "1. <a href=\"#section3\">Unification</a>\n",
    "1. <a href=\"#section4\">Rule Application</a>\n",
    "1. <a href=\"#section5\">Backward Chaining</a>\n",
    "1. <a href=\"#grade\">Grade Your Homework</a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are two types of data: visible data (provided to you), and hidden data (available only to the autograder on Gradescope).  If you get your code working for the visible data, it should also work for the hidden data.\n",
    "\n",
    "The data for this MP are a set of <a href=\"https://allenai.org/data/ruletaker\">closed-world reasoning environments</a> that were developed for the 2020 paper <a href=\"https://arxiv.org/abs/2002.05867\">Transformers as Soft Reasoners over Language</a> by Clark, Tafjord and Richardson.  Each world includes a set of facts, and a set of questions that can be asked on the basis of those facts.\n",
    "\n",
    "In order to help you load the data, we provide you with a utility function called `reader.py`.  Since its methods are correctly documented by <a href=\"https://en.wikipedia.org/wiki/Docstring\">docstrings</a>, you can find information about each function by using `help`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on module reader:\n",
      "\n",
      "NAME\n",
      "    reader\n",
      "\n",
      "DESCRIPTION\n",
      "    Read in reasoning environments from one of the RuleTaker metadata jsonl files\n",
      "    distributed by https://allenai.org/data/ruletaker.\n",
      "\n",
      "FUNCTIONS\n",
      "    load_datafile(filename)\n",
      "        Load a RuleTaker jsonl file in a format suitable for forward-chaining.\n",
      "        \n",
      "        @param filename (str): the file containing the data.  Must be in jsonl format.\n",
      "        \n",
      "        @return worlds (dict): a dict mapping world IDs to worlds\n",
      "          Each world is a dict containing two entries: \n",
      "          world['rules'] - a dict mapping rule IDs to rules.\n",
      "            Each rule is a dict:\n",
      "            rule['text'] is the natural language text of the rule\n",
      "            rule['antecedents'] contains the rule antecedents (a list of propositions)\n",
      "            rule['consequent'] contains the rule consequent (a proposition).\n",
      "          world['questions'] - a dict mapping question IDs to questions.\n",
      "            Each question is a dict:\n",
      "            question['text'] is the natural language text of the question\n",
      "            question['proofs'] is a string specifying the reference proof of the provided answer\n",
      "            question['query'] is a list specifying the rule in standard proposition format\n",
      "            question['answer'] indicates the correct answer, which may be one of:\n",
      "               True: query is true\n",
      "               False: query is false\n",
      "               \"NAF\": supported by a negative statement which wasn't disproven\n",
      "               \"CWA\": search for a proof exceeded maximum depth\n",
      "          Standard proposition format is a list of length 4: [head, predicate, tail, negation]\n",
      "            where negation is True or False.\n",
      "    \n",
      "    parse_rule(s)\n",
      "        Parse the representation of a rule or rule\n",
      "        \n",
      "        @param s (str) - string of the form ((ante1, ante2, ...) -> cons)\n",
      "           where ante1, ... and cons are all strings representing logical triples\n",
      "        \n",
      "        @return antecedents (list) - list of antecedent propositions\n",
      "        @return consequent (list) - consequent proposition\n",
      "           where each proposition is a list of the form [ head, predicate, tail, negation ]\n",
      "    \n",
      "    parse_triple(s)\n",
      "        Parse the representation of a logical triple.\n",
      "        \n",
      "        @param s (str) - a string of the form '(\"head\" \"predicate\" \"tail\" \"negation\")'\n",
      "        \n",
      "        @return t (list) - a proposition, a list of the form [head, predicate, tail, negation]\n",
      "\n",
      "FILE\n",
      "    /Users/jhasegaw/Dropbox/mark/teaching/ece448/ece448labs/spring23/mp07/src/reader.py\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import reader, importlib\n",
    "importlib.reload(reader)\n",
    "help(reader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, that's pretty straightforward.   Let's use it to load the `data` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(reader)\n",
    "data_worlds = reader.load_datafile('data/meta-train.jsonl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There were 6314 logical worlds loaded.\n",
      "Some of the world IDs are: ['RelNeg-D2-1742', 'RelNoneg-D2-2133', 'AttNoneg-D2-163', 'RelNoneg-D2-820', 'RelNoneg-D2-1342']\n"
     ]
    }
   ],
   "source": [
    "print(\"There were\",len(data_worlds),\"logical worlds loaded.\")\n",
    "ids = list(data_worlds.keys())\n",
    "print(\"Some of the world IDs are:\",ids[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_worlds[RelNoneg-D2-2133] contains the following rules:\n",
      "{'rule1': {'antecedents': [['something', 'eats', 'tiger', True]],\n",
      "           'consequent': ['something', 'sees', 'tiger', True],\n",
      "           'text': 'If something eats the tiger then it sees the tiger.'},\n",
      " 'rule2': {'antecedents': [['something', 'visits', 'bald eagle', True]],\n",
      "           'consequent': ['something', 'eats', 'tiger', True],\n",
      "           'text': 'If something visits the bald eagle then it eats the '\n",
      "                   'tiger.'},\n",
      " 'rule3': {'antecedents': [['something', 'is', 'rough', True]],\n",
      "           'consequent': ['something', 'eats', 'tiger', True],\n",
      "           'text': 'If something is rough then it eats the tiger.'},\n",
      " 'triple1': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'eats', 'tiger', True],\n",
      "             'text': 'The bald eagle eats the tiger.'},\n",
      " 'triple10': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'is', 'green', True],\n",
      "              'text': 'The tiger is green.'},\n",
      " 'triple11': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'is', 'kind', True],\n",
      "              'text': 'The tiger is kind.'},\n",
      " 'triple12': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'is', 'rough', True],\n",
      "              'text': 'The tiger is rough.'},\n",
      " 'triple13': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'is', 'young', True],\n",
      "              'text': 'The tiger is young.'},\n",
      " 'triple14': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'sees', 'bald eagle', True],\n",
      "              'text': 'The tiger sees the bald eagle.'},\n",
      " 'triple15': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'visits', 'bald eagle', True],\n",
      "              'text': 'The tiger visits the bald eagle.'},\n",
      " 'triple2': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'is', 'blue', True],\n",
      "             'text': 'The bald eagle is blue.'},\n",
      " 'triple3': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'is', 'green', True],\n",
      "             'text': 'The bald eagle is green.'},\n",
      " 'triple4': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'is', 'kind', True],\n",
      "             'text': 'The bald eagle is kind.'},\n",
      " 'triple5': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'is', 'rough', True],\n",
      "             'text': 'The bald eagle is rough.'},\n",
      " 'triple6': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'sees', 'tiger', True],\n",
      "             'text': 'The bald eagle sees the tiger.'},\n",
      " 'triple7': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'visits', 'tiger', True],\n",
      "             'text': 'The bald eagle visits the tiger.'},\n",
      " 'triple8': {'antecedents': [],\n",
      "             'consequent': ['tiger', 'eats', 'bald eagle', True],\n",
      "             'text': 'The tiger eats the bald eagle.'},\n",
      " 'triple9': {'antecedents': [],\n",
      "             'consequent': ['tiger', 'is', 'blue', True],\n",
      "             'text': 'The tiger is blue.'}}\n",
      "\n",
      "... and the following questions:\n",
      "{'Q1': {'answer': True,\n",
      "        'proofs': '[(triple9)]',\n",
      "        'query': ['tiger', 'is', 'blue', True],\n",
      "        'text': 'The tiger is blue?'},\n",
      " 'Q10': {'answer': 'CWA',\n",
      "         'proofs': '[@0: The bald eagle visits the bald eagle.[CWA. Example of '\n",
      "                   'deepest failure = (FAIL)]]',\n",
      "         'query': ['bald eagle', 'visits', 'bald eagle', True],\n",
      "         'text': 'The bald eagle visits the bald eagle?'},\n",
      " 'Q2': {'answer': False,\n",
      "        'proofs': '[(triple12)]',\n",
      "        'query': ['tiger', 'is', 'rough', False],\n",
      "        'text': 'The tiger is not rough?'},\n",
      " 'Q3': {'answer': True,\n",
      "        'proofs': '[(((triple12) -> rule3) OR ((triple15) -> rule2))]',\n",
      "        'query': ['tiger', 'eats', 'tiger', True],\n",
      "        'text': 'The tiger eats the tiger?'},\n",
      " 'Q4': {'answer': False,\n",
      "        'proofs': '[(((triple12) -> rule3) OR ((triple15) -> rule2))]',\n",
      "        'query': ['tiger', 'eats', 'tiger', False],\n",
      "        'text': 'The tiger does not eat the tiger?'},\n",
      " 'Q5': {'answer': True,\n",
      "        'proofs': '[(((((triple12) -> rule3)) -> rule1) OR ((((triple15) -> '\n",
      "                  'rule2)) -> rule1))]',\n",
      "        'query': ['tiger', 'sees', 'tiger', True],\n",
      "        'text': 'The tiger sees the tiger?'},\n",
      " 'Q6': {'answer': False,\n",
      "        'proofs': '[(((((triple12) -> rule3)) -> rule1) OR ((((triple15) -> '\n",
      "                  'rule2)) -> rule1))]',\n",
      "        'query': ['tiger', 'sees', 'tiger', False],\n",
      "        'text': 'The tiger does not see the tiger?'},\n",
      " 'Q7': {'answer': 'CWA',\n",
      "        'proofs': '[@0: The tiger visits the tiger.[CWA. Example of deepest '\n",
      "                  'failure = (FAIL)]]',\n",
      "        'query': ['tiger', 'visits', 'tiger', False],\n",
      "        'text': 'The tiger does not visit the tiger?'},\n",
      " 'Q8': {'answer': 'CWA',\n",
      "        'proofs': '[@0: The bald eagle eats the bald eagle.[CWA. Example of '\n",
      "                  'deepest failure = (FAIL)]]',\n",
      "        'query': ['bald eagle', 'eats', 'bald eagle', True],\n",
      "        'text': 'The bald eagle eats the bald eagle?'},\n",
      " 'Q9': {'answer': 'CWA',\n",
      "        'proofs': '[@0: The bald eagle is young.[CWA. Example of deepest '\n",
      "                  'failure = (FAIL)]]',\n",
      "        'query': ['bald eagle', 'is', 'young', False],\n",
      "        'text': 'The bald eagle is not young?'}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "id = 'RelNoneg-D2-2133'\n",
    "print(\"data_worlds[%s] contains the following rules:\"%(id))\n",
    "pprint.PrettyPrinter(indent=1).pprint(data_worlds[id]['rules'])\n",
    "print(\"\")\n",
    "print(\"... and the following questions:\")\n",
    "pprint.PrettyPrinter(indent=1).pprint(data_worlds[id]['questions'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, each logical world consists of a list of **rules**, and a list of **questions**.\n",
    "\n",
    "Each rule consists of a **consequent**, which is true only if its **antecedents** are true.  Both the antecedents and the consequent are **propositions**.  If there are no antecedents, then the consequent is always true.  The **text** of the rule is provided only to help you understand the formal **proposition** notation; no part of the MP will ever use the text for any other reason.\n",
    "\n",
    "Each question consists of a **query**, which is a proposition that may or may not be true in this world.  If a query is not provably true, then it is considered to be false (the so-called <a href=\"https://en.wikipedia.org/wiki/Closed-world_assumption\">closed-world assumption</a>.)\n",
    "\n",
    "In our notation, a **proposition** is a list of length 4 consisting of a **head** (the subject of the verb), a **predicate** (usually a verb), a **tail** (the object of the verb), and a **negation indicator**.  The negation indicator specifies whether the sentence \"head predicate tail\" should be considered True or False.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardizing Variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that many of the rules we just loaded include the generic variable **something**.  Consider these rules for example:\n",
    "\n",
    "```\n",
    "'rule1': {'antecedents': [['something', 'needs', 'bald eagle', True],\n",
    "                          ['something', 'is', 'cold', False]],\n",
    "          'consequent': ['something', 'visits', 'bald eagle', True],\n",
    "          'text': 'If something needs the bald eagle and it is not cold then '\n",
    "                  'it visits the bald eagle.'},\n",
    "'rule2': {'antecedents': [['something', 'is', 'nice', True],\n",
    "                          ['something', 'eats', 'squirrel', False]],\n",
    "          'consequent': ['squirrel', 'eats', 'bald eagle', True],\n",
    "          'text': 'If something is nice and it does not eat the squirrel then '\n",
    "                  'the squirrel eats the bald eagle.'},\n",
    "```\n",
    "\n",
    "In logical notation, we could write these rules as\n",
    "\n",
    "$$\\forall x:\\text{needs}(x,\\text{bald eagle})\\wedge\\neg\\text{is}(x,\\text{cold})\\Rightarrow\\text{visits}(x,\\text{bald eagle})$$\n",
    "$$\\forall x:\\text{is}(x,\\text{nice})\\wedge\\neg\\text{eats}(x,\\text{squirrel})\\Rightarrow\\text{eats}(\\text{squirrel},\\text{bald eagle})$$\n",
    "\n",
    "In our corpus, the only variable you will ever see is the word **something**.  Notice the following points:\n",
    "\n",
    "* If the word **something** occurs in both the antecedents and the consequent of a rule, then it must be the same something.  In other words, you need to bind those two **somethings** to the same term.\n",
    "* If the word **something** occurs in two different rules, then those two **somethings** could refer to different things.  They don't need to refer to the same term.\n",
    "\n",
    "In order to make it clear that the **somethings** in different rules refer to possibly different objects, the first thing we need to do is to standardize variables.  This is your first task.  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we'll load the file `submitted.py`.\n",
    "\n",
    "The file `submitted.py` is the only part of your work that the autograder will see. The only purpose of this notebook is to help you debug `submitted.py`.  Once you have revised `submitted.py` enough to make this notebook work, then you should go to the command line, and type `python grade.py`.  Once that command returns without errors, then  you can go ahead and submit your file `submitted.py` to the autograder.  You can submit to the autograder as often as you want, but it will save you trouble if you debug as much as you can on your local machine, before you submit to the autograder.\n",
    "\n",
    "We will use `importlib` in order to reload your `submitted.py` over and over again.  That way, every time you make a modification in `submitted.py`, you can just re-run  the corresponding block of this notebook, and it will reload `submitted.py` with your modified code.  \n",
    "\n",
    "Since the file is called `submitted.py`, python considers it to contain a module called `submitted`.  As shown, you can read the module's docstring by printing `submitted.__doc__`.  You can also type `help(submitted)` to get a lot of information about the module, including its docstring, a list of all the functions it defines, and all of their docstrings.  For  more about docstrings, see, for example, https://www.python.org/dev/peps/pep-0257/."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "This is the module you'll submit to the autograder.\n",
      "\n",
      "There are several function definitions, here, that raise RuntimeErrors.  You should replace\n",
      "each \"raise RuntimeError\" line with a line that performs the function specified in the\n",
      "function's docstring.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import submitted\n",
    "import importlib\n",
    "importlib.reload(submitted)\n",
    "print(submitted.__doc__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now it's time for you to open `submitted.py`, and start editing it.  You can open it in another Jupyter window by choosing \"Open from Path\" from the \"File\" menu, and then typing `submitted.py`.  Alternatively, you can use any text editor.\n",
    "\n",
    "Once you have it open, try editing the function `standardize_variables` so that its functionality matches its docstring.  Here is what it's docstring says:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function standardize_variables in module submitted:\n",
      "\n",
      "standardize_variables(nonstandard_rules)\n",
      "    @param nonstandard_rules (dict) - dict from ruleIDs to rules\n",
      "        Each rule is a dict:\n",
      "        rule['antecedents'] contains the rule antecedents (a tuple of propositions)\n",
      "        rule['consequent'] contains the rule consequent (a proposition).\n",
      "    \n",
      "    @return standardized_rules (dict) - an exact copy of nonstandard_rules,\n",
      "        except that the antecedents and consequent of every rule have been changed\n",
      "        to replace the word \"something\" with some variable name that is\n",
      "        unique to the rule, and not shared by any other rule.\n",
      "    @return variables (list) - a list of the variable names that were created.\n",
      "        This list should contain only the variables that were used in rules.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.standardize_variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit `standardize_variables` so that it does the task specified in its docstring.  When you get the code working, check to make sure that `standardize_variables(worlds[0]['rules'])` works.\n",
    "\n",
    "Note: your version of `standardize_variables` does **not** need to produce the same variable names as those shown here.  You just need to make sure that (1) in any given rule, there is only one unique variable name, (2) no two rules have instances of the same variable name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The variables for world RelNoneg-D2-2133 are:\n",
      "['x0000', 'x0001', 'x0002']\n",
      "\n",
      "... and the standardized rules are:\n",
      "{'rule1': {'antecedents': [['x0000', 'eats', 'tiger', True]],\n",
      "           'consequent': ['x0000', 'sees', 'tiger', True],\n",
      "           'text': 'If something eats the tiger then it sees the tiger.'},\n",
      " 'rule2': {'antecedents': [['x0001', 'visits', 'bald eagle', True]],\n",
      "           'consequent': ['x0001', 'eats', 'tiger', True],\n",
      "           'text': 'If something visits the bald eagle then it eats the '\n",
      "                   'tiger.'},\n",
      " 'rule3': {'antecedents': [['x0002', 'is', 'rough', True]],\n",
      "           'consequent': ['x0002', 'eats', 'tiger', True],\n",
      "           'text': 'If something is rough then it eats the tiger.'},\n",
      " 'triple1': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'eats', 'tiger', True],\n",
      "             'text': 'The bald eagle eats the tiger.'},\n",
      " 'triple10': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'is', 'green', True],\n",
      "              'text': 'The tiger is green.'},\n",
      " 'triple11': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'is', 'kind', True],\n",
      "              'text': 'The tiger is kind.'},\n",
      " 'triple12': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'is', 'rough', True],\n",
      "              'text': 'The tiger is rough.'},\n",
      " 'triple13': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'is', 'young', True],\n",
      "              'text': 'The tiger is young.'},\n",
      " 'triple14': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'sees', 'bald eagle', True],\n",
      "              'text': 'The tiger sees the bald eagle.'},\n",
      " 'triple15': {'antecedents': [],\n",
      "              'consequent': ['tiger', 'visits', 'bald eagle', True],\n",
      "              'text': 'The tiger visits the bald eagle.'},\n",
      " 'triple2': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'is', 'blue', True],\n",
      "             'text': 'The bald eagle is blue.'},\n",
      " 'triple3': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'is', 'green', True],\n",
      "             'text': 'The bald eagle is green.'},\n",
      " 'triple4': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'is', 'kind', True],\n",
      "             'text': 'The bald eagle is kind.'},\n",
      " 'triple5': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'is', 'rough', True],\n",
      "             'text': 'The bald eagle is rough.'},\n",
      " 'triple6': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'sees', 'tiger', True],\n",
      "             'text': 'The bald eagle sees the tiger.'},\n",
      " 'triple7': {'antecedents': [],\n",
      "             'consequent': ['bald eagle', 'visits', 'tiger', True],\n",
      "             'text': 'The bald eagle visits the tiger.'},\n",
      " 'triple8': {'antecedents': [],\n",
      "             'consequent': ['tiger', 'eats', 'bald eagle', True],\n",
      "             'text': 'The tiger eats the bald eagle.'},\n",
      " 'triple9': {'antecedents': [],\n",
      "             'consequent': ['tiger', 'is', 'blue', True],\n",
      "             'text': 'The tiger is blue.'}}\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "import copy, importlib\n",
    "importlib.reload(submitted)\n",
    "worlds = {}\n",
    "for id in data_worlds.keys():\n",
    "    worlds[id] = copy.deepcopy(data_worlds[id])\n",
    "    rules, variables = submitted.standardize_variables(data_worlds[id]['rules'])\n",
    "    worlds[id]['variables'] = variables\n",
    "    worlds[id]['rules'] = rules\n",
    "    \n",
    "id = 'RelNoneg-D2-2133'\n",
    "print('The variables for world %s are:'%(id))\n",
    "print(worlds[id]['variables'])\n",
    "print(\"\")\n",
    "print(\"... and the standardized rules are:\")\n",
    "pprint.PrettyPrinter(indent=1).pprint(worlds[id]['rules'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The autograder checks to make sure that your standardized rules are identical to the input rules except that (1) in any given rule, there is only one unique variable name, (2) no two rules have instances of the same variable name.\n",
    "\n",
    "You can test it by running `grade.py`, and looking at the output for `test_standardization`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"tests\": [\r\n",
      "        {\r\n",
      "            \"name\": \"test_apply (test_visible.TestStep)\",\r\n",
      "            \"score\": 12.5,\r\n",
      "            \"max_score\": 12.5\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"test_backward_chain (test_visible.TestStep)\",\r\n",
      "            \"score\": 12.5,\r\n",
      "            \"max_score\": 12.5\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"test_standardization (test_visible.TestStep)\",\r\n",
      "            \"score\": 12.5,\r\n",
      "            \"max_score\": 12.5\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"test_unify (test_visible.TestStep)\",\r\n",
      "            \"score\": 12.5,\r\n",
      "            \"max_score\": 12.5\r\n",
      "        }\r\n",
      "    ],\r\n",
      "    \"leaderboard\": [],\r\n",
      "    \"visibility\": \"visible\",\r\n",
      "    \"execution_time\": \"0.01\",\r\n",
      "    \"score\": 50.0\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!python grade.py --json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unification tests two propositions, a `query` and a `datum`, to see whether there is any third proposition (the `unification`) that would imply both.  For example, consider these two propositions:\n",
    "\n",
    "$$A: \\exists x: \\text{visits}(x,\\text{bald eagle})$$\n",
    "$$B: \\exists x: \\text{visits}(\\text{squirrel},x)$$\n",
    "\n",
    "These two propositions are both satisfied by the claim that squirrel visits bald eagle.  The unification of these two propositions is\n",
    "\n",
    "$$C: \\text{visits}(\\text{squirrel},\\text{bald eagle})$$\n",
    "\n",
    "Notice the direction of implicature.  Unification means that $C\\Rightarrow A$ and $C\\Rightarrow B$.  The opposite is not true: $A\\wedge B\\not\\Rightarrow C$!\n",
    "\n",
    "\n",
    "If a pair of propositions cannot be unified, then the `unify` function should just return `None`, to indicate that no unification is possible.  For example, proposition $A$ says that something visits the bald eagle, but suppose we want to test whether or not there is something that does **not** visit the bald eagle:\n",
    "\n",
    "$$D: \\exists x: \\neg\\text{visits}(x,\\text{bald eagle})$$\n",
    "\n",
    "The unification of statements $D$ and $B$ is `None`, because there is no single proposition we could provide that would prove both $D$ and $B$.\n",
    "\n",
    "It is possible to unify two statements without resolving all variables.  For example, consider:\n",
    "\n",
    "$$E: \\exists y,z: \\text{visits}(y,z)$$\n",
    "\n",
    "The unification of statements $A$ and $E$ is:\n",
    "\n",
    "$$F: \\exists y:\\text{visits}(y,\\text{bald eagle})$$\n",
    "\n",
    "Statement $F$ has exactly the same meaning as statement $A$.  Nevertheless, it is a valid unification of statements $A$ and $E$: notice that $F\\Rightarrow A$ and $F\\Rightarrow E$, so we know that the statements are equivalent in that very precise sense."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function unify in module submitted:\n",
      "\n",
      "unify(query, datum, variables)\n",
      "    @param query: proposition that you're trying to match.\n",
      "      The input query should not be modified by this function; consider deepcopy.\n",
      "    @param datum: proposition against which you're trying to match the query.\n",
      "      The input datum should not be modified by this function; consider deepcopy.\n",
      "    @param variables: list of strings that should be considered variables.\n",
      "      All other strings should be considered constants.\n",
      "    \n",
      "    Unification succeeds if (1) every variable x in the unified query is replaced by a \n",
      "    variable or constant from datum, which we call subs[x], and (2) for any variable y\n",
      "    in datum that matches to a constant in query, which we call subs[y], then every \n",
      "    instance of y in the unified query should be replaced by subs[y].\n",
      "    \n",
      "    @return unification (tuple): unified query, or None if unification fails.\n",
      "    @return subs (dict): mapping from variables to values, or None if unification fails.\n",
      "       If unification is possible, then answer already has all copies of x replaced by\n",
      "       subs[x], thus the only reason to return subs is to help the calling function\n",
      "       to update other rules so that they obey the same substitutions.\n",
      "    \n",
      "    Examples:\n",
      "    \n",
      "    unify(['x', 'eats', 'y', False], ['a', 'eats', 'b', False], ['x','y','a','b'])\n",
      "      unification = [ 'a', 'eats', 'b', False ]\n",
      "      subs = { \"x\":\"a\", \"y\":\"b\" }\n",
      "    unify(['bobcat','eats','y',True],['a','eats','squirrel',True], ['x','y','a','b'])\n",
      "      unification = ['bobcat','eats','squirrel',True]\n",
      "      subs = { 'a':'bobcat', 'y':'squirrel' }\n",
      "    unify(['x','eats','x',True],['a','eats','a',True],['x','y','a','b'])\n",
      "      unification = ['a','eats','a',True]\n",
      "      subs = { 'x':'a' }\n",
      "    unify(['x','eats','x',True],['a','eats','bobcat',True],['x','y','a','b'])\n",
      "      unification = ['bobcat','eats','bobcat',True],\n",
      "      subs = {'x':'a', 'a':'bobcat'}\n",
      "      When the 'x':'a' substitution is detected, the query is changed to \n",
      "      ['a','eats','a',True].  Then, later, when the 'a':'bobcat' substitution is \n",
      "      detected, the query is changed to ['bobcat','eats','bobcat',True], which \n",
      "      is the value returned as the answer.\n",
      "    unify(['a','eats','bobcat',True],['x','eats','x',True],['x','y','a','b'])\n",
      "      unification = ['bobcat','eats','bobcat',True],\n",
      "      subs = {'a':'x', 'x':'bobcat'}\n",
      "      When the 'a':'x' substitution is detected, the query is changed to \n",
      "      ['x','eats','bobcat',True].  Then, later, when the 'x':'bobcat' substitution \n",
      "      is detected, the query is changed to ['bobcat','eats','bobcat',True], which is \n",
      "      the value returned as the answer.\n",
      "    unify([...,True],[...,False],[...]) should always return None, None, regardless of the \n",
      "      rest of the contents of the query or datum.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.unify)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Modify the `unify` function so that it performs as specified by the docstring.  Once you have modified it, you can test it with some of the examples provided in the docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unification is: ['a', 'eats', 'b', False]\n",
      "Subs is: {'x': 'a', 'y': 'b'}\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "unification, subs = submitted.unify(['x','eats','y',False],['a','eats','b',False],['x','y','a','b'])\n",
    "print('Unification is:',unification)\n",
    "print('Subs is:',subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unification is: ['bobcat', 'eats', 'squirrel', True]\n",
      "Subs is: {'a': 'bobcat', 'y': 'squirrel'}\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "unification, subs = submitted.unify(['bobcat','eats','y',True],['a','eats','squirrel',True],['x','y','a','b'])\n",
    "print('Unification is:',unification)\n",
    "print('Subs is:',subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unification is: ['bobcat', 'eats', 'bobcat', True]\n",
      "Subs is: {'x': 'a', 'a': 'bobcat'}\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "unification, subs = submitted.unify(['x','eats','x',True],['a','eats','bobcat',True],['x','y','a','b'])\n",
    "print('Unification is:',unification)\n",
    "print('Subs is:',subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unification is: ['bobcat', 'eats', 'bobcat', True]\n",
      "Subs is: {'a': 'x', 'x': 'bobcat'}\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "unification, subs = submitted.unify(['a','eats','bobcat',True],['x','eats','x',True],['x','y','a','b'])\n",
    "print('Unification is:',unification)\n",
    "print('Subs is:',subs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unification is: None\n",
      "Subs is: None\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "unification, subs = submitted.unify(['a','eats','bobcat',True],['x','eats','x',False],['x','y','a','b'])\n",
    "print('Unification is:',unification)\n",
    "print('Subs is:',subs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rule Application"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this MP we will be implementing backward-chaining.  When we apply a rule, therefore, we will apply it backward.  Suppose we have a set of propositions that we are trying to prove; call those the `goals`.  We test whether or not a rule is useful to us by the following procedure:\n",
    "\n",
    "1. Test to see whether the consequent of the rule can be unified with a goal, i.e., is there any proposition that, if it were true, would imply both the rule consequent and the goal?\n",
    "1. Take the variable substitutions from the rule application, and modify the rule antecedents using those same substitutions.  Now we have a set of rule antecedent propositions that, if true, would imply the goal.\n",
    "1. Replace the old goal with the new goals that were created by this process.\n",
    "\n",
    "For example, suppose we have the following rule:\n",
    "\n",
    "$$\\forall x: \\text{is}(\\text{squirrel},\\text{nice})\\wedge\\text{is}(x,\\text{cold})\\Rightarrow\\text{visits}(x,\\text{squirrel})$$\n",
    "\n",
    "Suppose that we are trying to prove the following list of goal statements:\n",
    "\n",
    "$$\\text{goals}[0]=\\text{visits}(\\text{bobcat},\\text{bald eagle})$$\n",
    "$$\\text{goals}[1]=\\text{visits}(\\text{bobcat},\\text{squirrel})$$\n",
    "\n",
    "We can't apply the rule to $\\text{goals}[0]$, because the rule talks about visiting squirrel.  We can apply the rule to goal $\\text{goals}[1]$, however.  Once we have completed that application, the list of goals now reads:\n",
    "\n",
    "$$\\text{newgoals}[0]=\\text{visits}(\\text{bobcat},\\text{bald eagle})$$\n",
    "$$\\text{newgoals}[1]=\\text{is}(\\text{squirrel},\\text{nice})$$\n",
    "$$\\text{newgoals}[2]=\\text{is}(\\text{bobcat},\\text{cold})$$\n",
    "\n",
    "If we can find a way to prove `newgoals`, that will constitute a proof of `goals`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function apply in module submitted:\n",
      "\n",
      "apply(rule, goals, variables)\n",
      "    @param rule: A rule that is being tested to see if it can be applied\n",
      "      This function should not modify rule; consider deepcopy.\n",
      "    @param goals: A list of propositions against which the rule's consequent will be tested\n",
      "      This function should not modify goals; consider deepcopy.\n",
      "    @param variables: list of strings that should be treated as variables\n",
      "    \n",
      "    Rule application succeeds if the rule's consequent can be unified with any one of the goals.\n",
      "    \n",
      "    @return applications: a list, possibly empty, of the rule applications that\n",
      "       are possible against the present set of goals.\n",
      "       Each rule application is a copy of the rule, but with both the antecedents \n",
      "       and the consequent modified using the variable substitutions that were\n",
      "       necessary to unify it to one of the goals. Note that this might require \n",
      "       multiple sequential substitutions, e.g., converting ('x','eats','squirrel',False)\n",
      "       based on subs=={'x':'a', 'a':'bobcat'} yields ('bobcat','eats','squirrel',False).\n",
      "       The length of the applications list is 0 <= len(applications) <= len(goals).  \n",
      "       If every one of the goals can be unified with the rule consequent, then \n",
      "       len(applications)==len(goals); if none of them can, then len(applications)=0.\n",
      "    @return goalsets: a list of lists of new goals, where len(newgoals)==len(applications).\n",
      "       goalsets[i] is a copy of goals (a list) in which the goal that unified with \n",
      "       applications[i]['consequent'] has been removed, and replaced by \n",
      "       the members of applications[0]['antecedents'].\n",
      "    \n",
      "    Example:\n",
      "    rule={\n",
      "      'antecedents':[['x','is','nice',True],['x','is','hungry',False]],\n",
      "      'consequent':['x','eats','squirrel',False]\n",
      "    }\n",
      "    goals=[\n",
      "      ['bobcat','eats','squirrel',False],\n",
      "      ['bobcat','visits','squirrel',True],\n",
      "      ['bald eagle','eats','squirrel',False]\n",
      "    ]\n",
      "    variables=['x','y','a','b']\n",
      "    \n",
      "    applications, newgoals = submitted.apply(rule, goals, variables)\n",
      "    \n",
      "    applications==[\n",
      "      {\n",
      "        'antecedents':[['bobcat','is','nice',True],['bobcat','is','hungry',False]],\n",
      "        'consequent':['bobcat','eats','squirrel',False]\n",
      "      },\n",
      "      {\n",
      "        'antecedents':[['bald eagle','is','nice',True],['bald eagle','is','hungry',False]],\n",
      "        'consequent':['bald eagle','eats','squirrel',False]\n",
      "      }\n",
      "    ]\n",
      "    newgoals==[\n",
      "      [\n",
      "        ['bobcat','visits','squirrel',True],\n",
      "        ['bald eagle','eats','squirrel',False]\n",
      "        ['bobcat','is','nice',True],\n",
      "        ['bobcat','is','hungry',False]\n",
      "      ],[\n",
      "        ['bobcat','eats','squirrel',False]\n",
      "        ['bobcat','visits','squirrel',True],\n",
      "        ['bald eagle','is','nice',True],\n",
      "        ['bald eagle','is','hungry',False]\n",
      "      ]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.apply)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Edit your copy of `apply`, and then test it using the example from the docstring:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The possible applications of this rule are:\n",
      "[{'antecedents': [['bobcat', 'is', 'nice', True],\n",
      "                  ['bobcat', 'is', 'hungry', False]],\n",
      "  'consequent': ['bobcat', 'eats', 'squirrel', False]},\n",
      " {'antecedents': [['bald eagle', 'is', 'nice', True],\n",
      "                  ['bald eagle', 'is', 'hungry', False]],\n",
      "  'consequent': ['bald eagle', 'eats', 'squirrel', False]}]\n",
      "The resulting modified goalsets are:\n",
      "[[['bobcat', 'visits', 'squirrel', True],\n",
      "  ['bald eagle', 'eats', 'squirrel', False],\n",
      "  ['bobcat', 'is', 'nice', True],\n",
      "  ['bobcat', 'is', 'hungry', False]],\n",
      " [['bobcat', 'eats', 'squirrel', False],\n",
      "  ['bobcat', 'visits', 'squirrel', True],\n",
      "  ['bald eagle', 'is', 'nice', True],\n",
      "  ['bald eagle', 'is', 'hungry', False]]]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "importlib.reload(submitted)\n",
    "\n",
    "rule={\n",
    "      'antecedents':[['x','is','nice',True],['x','is','hungry',False]],\n",
    "      'consequent':['x','eats','squirrel',False]\n",
    "}\n",
    "goals=[\n",
    "      ['bobcat','eats','squirrel',False],\n",
    "      ['bobcat','visits','squirrel',True],\n",
    "      ['bald eagle','eats','squirrel',False]\n",
    "]\n",
    "variables=['x','y','a','b']\n",
    "\n",
    "applications, goalsets = submitted.apply(rule, goals, variables)\n",
    "\n",
    "print('The possible applications of this rule are:')\n",
    "pprint.PrettyPrinter(indent=1).pprint(applications)\n",
    "print('The resulting modified goalsets are:')\n",
    "pprint.PrettyPrinter(indent=1).pprint(goalsets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backward Chaining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Backward-chaining is the method of proving a goal statement by finding rules that could be applied in order to prove it.\n",
    "\n",
    "Backward-chaining is a search algorithm:\n",
    "* The **starting state** is the statement that you are trying to prove.\n",
    "* Every **action** is a rule application.  The result of an action is to create a new goalset.\n",
    "* Every **state** is a goalset.  A goalset is a list of propositions called \"goals\" such that, if every goal is proven true, then that constitutes a proof of the statement you are trying to prove.\n",
    "* The **ending state** is an empty goalset.  The ending state is achieved by transforming the starting state into a list of goals such that every goal in that list is a known true proposition, i.e., the consequent of a rule that has an empty antecedents list.\n",
    "\n",
    "In backward-chaining, it is possible that your frontier will empty out before you ever reach a goal state.  If that happens, it means that it is impossible to prove the query based on the propositions that are known in this world.  Because of our <a href=\"https://en.wikipedia.org/wiki/Closed-world_assumption\">closed-world assumption</a>, we pretend that our inability to prove the query is proof of its falsehood, so in that case, your `backward_chain` method should return the value `proof==None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function backward_chain in module submitted:\n",
      "\n",
      "backward_chain(query, rules, variables)\n",
      "    @param query: a proposition, you want to know if it is true\n",
      "    @param rules: dict mapping from ruleIDs to rules\n",
      "    @param variables: list of strings that should be treated as variables\n",
      "    \n",
      "    @return proof (list): a list of rule applications\n",
      "      that, when read in sequence, conclude by proving the truth of the query.\n",
      "      If no proof of the query was found, you should return proof=None.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "help(submitted.backward_chain)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this part of the MP is just to come up with an algorithm that can correctly distinguish between questions in which `worlds[i]['questions'][j]['answer']==True` and those in which `worlds[i]['questions'][j]['answer']==False`.  You should feel pretty free to implement this in whatever way you like, e.g., you can use BFS or A* search, you can choose to re-expand previously expanded nodes or not, your frontier can use tuples or you can define a Node class for the frontier, and so on.  The key is just to get the right answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The tiger eats the tiger?\n",
      "Reference answer is: True\n",
      "Reference proof is: [(((triple12) -> rule3) OR ((triple15) -> rule2))]\n",
      "My code says the answer is: True\n",
      "[{'antecedents': [],\n",
      "  'consequent': ['tiger', 'visits', 'bald eagle', True],\n",
      "  'text': 'The tiger visits the bald eagle.'},\n",
      " {'antecedents': [['tiger', 'visits', 'bald eagle', True]],\n",
      "  'consequent': ['tiger', 'eats', 'tiger', True],\n",
      "  'text': 'If something visits the bald eagle then it eats the tiger.'}]\n"
     ]
    }
   ],
   "source": [
    "import pprint\n",
    "importlib.reload(submitted)\n",
    "world = worlds['RelNoneg-D2-2133']\n",
    "question = world['questions']['Q3']\n",
    "print(question['text'])\n",
    "print('Reference answer is:',question['answer'])\n",
    "print('Reference proof is:',question['proofs'])\n",
    "proof = submitted.backward_chain(question['query'],world['rules'], world['variables'])\n",
    "if proof==None:\n",
    "    print('My code says the answer is: False')\n",
    "else:\n",
    "    print('My code says the answer is: True')\n",
    "    pprint.PrettyPrinter(indent=1).pprint(proof)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will be graded only on the questions whose answers are either `True` or `False`.  The questions whose answers are `NAF` or `CWA` are considered to be technically true, under the closed-world assumption, but the methods for proving their truth are beyond the scope of this MP."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q1 :  The tiger is blue?\n",
      "   Reference proof is: [(triple9)]\n",
      "   Reference answer is: True\n",
      "    My code says the answer is: True\n",
      "[{'text': 'The tiger is blue.',\n",
      "  'antecedents': [],\n",
      "  'consequent': ['tiger', 'is', 'blue', True]}]\n",
      "Q2 :  The tiger is not rough?\n",
      "   Reference proof is: [(triple12)]\n",
      "   Reference answer is: False\n",
      "    My code says the answer is: False\n",
      "Q3 :  The tiger eats the tiger?\n",
      "   Reference proof is: [(((triple12) -> rule3) OR ((triple15) -> rule2))]\n",
      "   Reference answer is: True\n",
      "    My code says the answer is: True\n",
      "[{'text': 'The tiger visits the bald eagle.',\n",
      "  'antecedents': [],\n",
      "  'consequent': ['tiger', 'visits', 'bald eagle', True]},\n",
      " {'text': 'If something visits the bald eagle then it eats the tiger.',\n",
      "  'antecedents': [['tiger', 'visits', 'bald eagle', True]],\n",
      "  'consequent': ['tiger', 'eats', 'tiger', True]}]\n",
      "Q4 :  The tiger does not eat the tiger?\n",
      "   Reference proof is: [(((triple12) -> rule3) OR ((triple15) -> rule2))]\n",
      "   Reference answer is: False\n",
      "    My code says the answer is: False\n",
      "Q5 :  The tiger sees the tiger?\n",
      "   Reference proof is: [(((((triple12) -> rule3)) -> rule1) OR ((((triple15) -> rule2)) -> rule1))]\n",
      "   Reference answer is: True\n",
      "    My code says the answer is: True\n",
      "[{'text': 'The tiger visits the bald eagle.',\n",
      "  'antecedents': [],\n",
      "  'consequent': ['tiger', 'visits', 'bald eagle', True]},\n",
      " {'text': 'If something visits the bald eagle then it eats the tiger.',\n",
      "  'antecedents': [['tiger', 'visits', 'bald eagle', True]],\n",
      "  'consequent': ['tiger', 'eats', 'tiger', True]},\n",
      " {'text': 'If something eats the tiger then it sees the tiger.',\n",
      "  'antecedents': [['tiger', 'eats', 'tiger', True]],\n",
      "  'consequent': ['tiger', 'sees', 'tiger', True]}]\n",
      "Q6 :  The tiger does not see the tiger?\n",
      "   Reference proof is: [(((((triple12) -> rule3)) -> rule1) OR ((((triple15) -> rule2)) -> rule1))]\n",
      "   Reference answer is: False\n",
      "    My code says the answer is: False\n"
     ]
    }
   ],
   "source": [
    "importlib.reload(submitted)\n",
    "world = worlds['RelNoneg-D2-2133']\n",
    "for (qid, question) in world['questions'].items():\n",
    "    if question['answer']==True or question['answer']==False:\n",
    "        print(qid, \": \",question['text'])\n",
    "        print(\"   Reference proof is:\",question['proofs'])\n",
    "        print('   Reference answer is:',question['answer'])\n",
    "        proof = submitted.backward_chain(question['query'],world['rules'],world['variables'])\n",
    "        if proof==None:\n",
    "            print('    My code says the answer is: False')\n",
    "        else:\n",
    "            print('    My code says the answer is: True')\n",
    "            pprint.pp(proof,indent=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='grade'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grade your homework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you've reached this point, and all of the above sections work, then you're ready to try grading your homework!  Before you submit it to Gradescope, try grading it on your own machine.  This will run some visible test cases (which you can read in `tests/test_visible.py`), and compare the results to the solutions (which you can read in `solution.json`).\n",
    "\n",
    "The exclamation point (!) tells python to run the following as a shell command.  Obviously you don't need to run the code this way -- this usage is here just to remind you that you can also, if you wish, run this command in a terminal window."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "....\r\n",
      "----------------------------------------------------------------------\r\n",
      "Ran 4 tests in 0.004s\r\n",
      "\r\n",
      "OK\r\n"
     ]
    }
   ],
   "source": [
    "!python grade.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you got any 'E' marks, it means that your code generated some runtime errors, and you need to debug those.\n",
    "\n",
    "If you got any 'F' marks, it means that your code ran without errors, but that it generated results that did not pass the test assertions listed in `tests/test_visible.py`.  Try debugging those.\n",
    "\n",
    "If neither of those things happened, and your result was a series of dots, then your code works perfectly.  \n",
    "\n",
    "If you're not sure, you can try running grade.py with the -j option.  This will produce a JSON results file, in which the best score you can get is 50."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\r\n",
      "    \"tests\": [\r\n",
      "        {\r\n",
      "            \"name\": \"test_apply (test_visible.TestStep)\",\r\n",
      "            \"score\": 12.5,\r\n",
      "            \"max_score\": 12.5\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"test_backward_chain (test_visible.TestStep)\",\r\n",
      "            \"score\": 12.5,\r\n",
      "            \"max_score\": 12.5\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"test_standardization (test_visible.TestStep)\",\r\n",
      "            \"score\": 12.5,\r\n",
      "            \"max_score\": 12.5\r\n",
      "        },\r\n",
      "        {\r\n",
      "            \"name\": \"test_unify (test_visible.TestStep)\",\r\n",
      "            \"score\": 12.5,\r\n",
      "            \"max_score\": 12.5\r\n",
      "        }\r\n",
      "    ],\r\n",
      "    \"leaderboard\": [],\r\n",
      "    \"visibility\": \"visible\",\r\n",
      "    \"execution_time\": \"0.01\",\r\n",
      "    \"score\": 50.0\r\n",
      "}\r\n"
     ]
    }
   ],
   "source": [
    "!python grade.py -j"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should try uploading `submitted.py` to <a href=\"https://www.gradescope.com/courses/486387\">Gradescope</a>.  \n",
    "\n",
    "Gradescope will run the same visible tests that you just ran on your own machine, plus some additional hidden tests.  It's possible that your code passes all the visible tests, but fails the hidden tests.  If that happens, then it probably means that you hard-coded a number into your function definition, instead of using the input parameter that you were supposed to use.  Debug by running your function with a variety of different input parameters, and see if you can get it to respond correctly in all cases.\n",
    "\n",
    "Once your code works perfectly on Gradescope, with no errors, then you are done with the MP.  Congratulations!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ad2bdc8ecc057115af97d19610ffacc2b4e99fae6737bb82f5d7fb13d2f2c186"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
